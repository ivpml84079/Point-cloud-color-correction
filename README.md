# Point-cloud-color-correction

"An Effective Hybrid Color Correction Algorithm for Color Point Clouds" (2023) by Kuo-Liang Chung and Ting-Chung Tang.

<div align=center>
<img src="https://github.com/ivpml84079/Point-cloud-color-correction/blob/main/Fig/Example.png">
</div>

The effect of color correction using our method on the color point cloud from the [SHOT](http://vision.deis.unibo.it/research/80-shot) dataset, the left 
ones are the pair of point cloud before color correction, and the right ones are the correction result.

## Environment & Library
* Windows 10, Visual Studio 2022 (v143), Windows SDK 10.0, ISO C++17

* [Point Cloud Library](https://pointclouds.org/) 1.13.0

* [OpenCV](https://opencv.org/) 4.6.0

## Data preprocess
1. After download the **dataset 5** from SHOT dataset, using the [CloudCompare](https://www.danielgm.net/cc/) to convert the file
   from Mesh vertex to point cloud, then put them in their corresponding folder.

2. Use any point cloud registration method to obtain the transformation matrix required for aligning arbitrary point cloud pairs. 
   Save this matrix as a ```.txt``` file and place it in the respective directory.

* Please refer to the file lacation and naming rules in the Mario folder for guidance.

## User define parameter
```overlap_dist``` is the distance used to determine whether any two points from different point clouds overlap or not. 

```overlap_th``` is the overlapping rate threshold used to determine whether to use Bi-group partition or Tri-group partition.

```close_color_constrain``` is the CIELAB color constrain used in <img src="https://latex.codecogs.com/gif.latex?G^{close}"/>.

```moderate_color_constrain``` is the CIELAB color constrain used in <img src="https://latex.codecogs.com/gif.latex?G^{moderate}"/>.

## Result comparsion
Since point clouds consist of points in 3D space, evaluating the effectiveness of color correction requires loading a pair of point 
clouds simultaneously to confirm its effects. We provided a set of comparison images for each dataset in Fig folder. 

To view all results, please follow the instructions below:

* You can inspect the pre-color-corrected state by loading both the ```aligned_source.ply``` and ```dark_target.ply``` generated by
  the program simultaneously.

* To view the color-corrected results result of our method, load ```aligned_source.ply``` along with either ```triClass_color_correction.ply```
  or ```biClass_color_correction.ply``` .

* The result of other comparative method: NN-based method, KNN-based method, HM-based method, and HHM-based method can be examined by
  loading ```aligned_source.ply``` along with the individual file ```nn_color_correction.ply```, ```knn_color_correction.ply```,
  ```Fecker_color_correction.ply```, and ```Ding_color_correction.ply``` .
  
  The AGL-based method can be examined by loading ```Yu_source.ply``` and ```Yu_target.ply``` .
  
* Above operations can be performed using CloudCompare.

All color corrected result can be accessed from [result](https://drive.google.com/drive/folders/1Fsl_6wpDb8jv56x0_hjYOaHO0HWVDRnY?usp=sharing).

## Contact
If you have any questions, please email us via   
Ting-Chung Tang: m11115097@mail.ntust.edu.tw  
Kuo-Liang Chung: klchung01@gmail.com



